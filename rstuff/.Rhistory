notRepresented <- 0
for(i in 1:numReplicates){
samp <- sample(indicies, 10, replace=TRUE)
for(j in 1:numInd){
if(!(indicies[j] %in% samp)){
notRepresented <- notRepresented+1
}
}
}
notRep#/(numInd*numReplicates)
}
bootCov(10,10)
bootCov <- function(numInd, numReplicates){
indicies <- 1:numInd
notRepresented <- 0
for(i in 1:numReplicates){
samp <- sample(indicies, 10, replace=TRUE)
for(j in 1:numInd){
if(!(indicies[j] %in% samp)){
notRepresented <- notRepresented+1
}
}
}
notRepresented/(numInd*numReplicates)
}
bootCov(10,10)
bootCov(10,10)
bootCov(10,10)
bootCov(10,10)
bootCov(10,10)
bootCov(10,10)
bootCov(10,100)
bootCov(10,100)
bootCov(100,100)
bootCov(100,100)
bootCov <- function(numInd, numReplicates, num2Sample){
indicies <- 1:numInd
notRepresented <- 0
for(i in 1:numReplicates){
samp <- sample(indicies, num2Sample, replace=TRUE)
for(j in 1:numInd){
if(!(indicies[j] %in% samp)){
notRepresented <- notRepresented+1
}
}
}
notRepresented/(numInd*numReplicates)
}
bootCov(100,100,100)
bootCov(100,100,100)
bootCov(100,100,100)
bootZeroCov <- function(nData, numBootReps, numInBootSamp){
## nData is how many data points in original data set/sample
## numBootReps is how many times to do bootstrap
## numInBootSamp is size of each bootstrap sample
## returns average % of data points not in bootstrap
indicies <- 1:nData
notRepresented <- 0
for(i in 1:numBootReps){
bootSamp <- sample(indicies, numInBootSamp, replace=TRUE)
for(j in 1:numInd){
if(!(indicies[j] %in% bootSamp)){
notRepresented <- notRepresented+1
}
}
}
notRepresented/(nData*numBootReps)
}
bootZeroCov(100,100,100)
bootZeroCov <- function(nData, numBootReps, numInBootSamp){
## nData is how many data points in original data set/sample
## numBootReps is how many times to do bootstrap
## numInBootSamp is size of each bootstrap sample
## returns average % of data points not in bootstrap
dataIndicies <- 1:nData
notRepresented <- 0
for(i in 1:numBootReps){
bootSamp <- sample(dataIndicies, numInBootSamp, replace=TRUE)
for(j in 1:nData){
if(!(dataIndicies[j] %in% bootSamp)){
notRepresented <- notRepresented+1
}
}
}
notRepresented/(nData*numBootReps)
}
bootZeroCov(100,100,100)
bootZeroCov(100,100,100)
bootZeroCov(nData=100, numBootReps=100, numInBootSamp=100)
bootZeroCov(nData=100, numBootReps=100, numInBootSamp=200)
bootZeroCov(nData=100, numBootReps=100, numInBootSamp=50)
library(GBM)
install.packages("GBM")
install.packages("gbm")
?gbm
library(gbm)
?gbm
library(medley)
?add.medley
x <- rnorm(1000)
y <- rnorm(1000)
x3 <- rnorm(1000)
y3 <- rnorm(1000)
x2 <- rnorm(100)
x1 <- rnorm(10)
y2 <- rnorm(100)
y1 <- rnorm(10)
lm1 <- lm(y1 ~ y2)
lm1 <- lm(y1 ~ x1)
lm2 <- lm(y2 ~ x2)
lm3 <- lm(y3 ~ x3)
lm1
summary(lm1)
summary(lm2)
summary(lm3)
x5 <- rnorm(100000)
y5 <- rnorm(100000)
lm5 <- lm(y5 ~ x5)
summary(lm5)
plot(x1,y1)
plot(x2,y2)
plot(x3,y3)
plot(x5,y5)
plot(x3,y3)
lines(x3,lm3$fitted)
plot(x2,y2)
lines(x2,lm2$fitted)
plot(x2,y2)
lines(x2,lm2$fitted)
x2 <- rnorm(100)
plot(x2,y2)
lines(x2,lm2$fitted)
lm2 <- lm(y2 ~ x2)
plot(x2,y2)
lm2 <- lm(y2 ~ x2)
lines(x2,lm2$fitted)
x2 <- rnorm(100)
y2 <- rnorm(100)
lm2 <- lm(y2 ~ x2)
plot(x2,y2)
lines(x2,lm2$fitted)
x2 <- rnorm(100)
y2 <- rnorm(100)
lm2 <- lm(y2 ~ x2)
plot(x2,y2)
lines(x2,lm2$fitted)
for(i in 1:100){
x <- rnorm(100)
y <- rnorm(100)
lm0 <- lm(y ~ x)
lines(x,y)
}
plot(x2,y2)
for(i in 1:10){
x <- rnorm(100)
y <- rnorm(100)
lm0 <- lm(y ~ x)
lines(x,y)
}
plot(x2,y2)
for(i in 1:10){
x <- rnorm(100)
y <- rnorm(100)
lm0 <- lm(y ~ x)
lines(x,lm0$fitted)
}
plot(x2,y2)
for(i in 1:10){
x <- rnorm(100)
y <- rnorm(100)
lm0 <- lm(y ~ x)
lines(x,lm0$fitted)
}
plot(x2,y2)
for(i in 1:10){
x <- rnorm(100)
y <- rnorm(100)
lm0 <- lm(y ~ x)
lines(x,lm0$fitted, col="grey")
}
160*15
2400/60
a <- c(2,4,6)
for(element in a){print(element)}
## Hi-C matrix
## This just partitions genome into bins
## Then for each paired read it adds 1 count to the i,j index in the matrix
##   corresponding to the 2 bins the paired reads end up in
## Another way of looking at it is this:
## Take all the reads in bin i and just find the paired bins
## This would be slightly different algorithmically then finding the bin for each read of the pair
generateRandomReadsBED <- function(chr, numReads, chrLength, readLength){
## chr is an integer chr#, numReads is how many to generate
## use BEDtools for better tool
## this just is quick and dirty
starts <- sort(as.integer(runif(n=numReads, min=1, max=chrLength-readLength+1)))
ends <- starts + readLength - 1
chr <- paste0("chr", as.character(chr))
chr <- rep(chr, times=numReads)
strand <- rbinom(numReads, 1, 0.5)
strand[strand == 1] <- '+'
strand[strand == 0] <- '-'
reads <- data.frame(chr=chr, start=starts, end=ends, strand=strand)
return(reads)
}
multiChrReads <- function(chrVec, numReads, chrLengthVec, readLength){
## returns approx number of reads
percentTotalLengths <- chrLengthVec/sum(chrLengthVec)
reads <- data.frame()
for(chr in 1:length(chrVec)){
reads <- rbind(reads, generateRandomReadsBED(chrVec[chr], numReads*percentTotalLengths[chr], chrLength[chr], readLength))
}
return(reads)
}
multiChrReads(c(1,2), 200, c(1000,3000), 50)
multiChrReads <- function(chrVec, numReads, chrLengthVec, readLength){
## returns approx number of reads
percentTotalLengths <- chrLengthVec/sum(chrLengthVec)
reads <- data.frame()
for(chr in 1:length(chrVec)){
reads <- rbind(reads, generateRandomReadsBED(chrVec[chr], numReads*percentTotalLengths[chr], chrLengthVec[chr], readLength))
}
return(reads)
}
multiChrReads(c(1,2), 200, c(1000,3000), 50)
## Then for each paired read it adds 1 count to the i,j index in the matrix
##   corresponding to the 2 bins the paired reads end up in
## Another way of looking at it is this:
## Take all the reads in bin i and just find the paired bins
## This would be slightly different algorithmically then finding the bin for each read of the pair
generateRandomReadsBED <- function(chr, numReads, chrLength, readLength){
## chr is an integer chr#, numReads is how many to generate
## use BEDtools for better tool
## this just is quick and dirty
starts <- as.integer(runif(n=numReads, min=1, max=chrLength-readLength+1))
ends <- starts + readLength - 1
chr <- paste0("chr", as.character(chr))
chr <- rep(chr, times=numReads)
strand <- rbinom(numReads, 1, 0.5)
strand[strand == 1] <- '+'
strand[strand == 0] <- '-'
reads <- data.frame(chr=chr, start=starts, end=ends, strand=strand)
return(reads)
}
multiChrReads(c(1,2), 200, c(1000,3000), 50)
generateRandomReadsBED <- function(chr, numReads, chrLength, readLength){
## chr is an integer chr#, numReads is how many to generate
## use BEDtools for better tool
## this just is quick and dirty
starts <- sort(as.integer(runif(n=numReads, min=1, max=chrLength-readLength+1)))
ends <- starts + readLength - 1
chr <- paste0("chr", as.character(chr))
chr <- rep(chr, times=numReads)
strand <- rbinom(numReads, 1, 0.5)
strand[strand == 1] <- '+'
strand[strand == 0] <- '-'
reads <- data.frame(chr=chr, start=starts, end=ends, strand=strand)
return(reads)
}
multiChrReads(c(1,2), 200, c(1000,3000), 50)
multiChrReads <- function(chrVec, numReads, chrLengthVec, readLength){
## returns approx number of reads
percentTotalLengths <- chrLengthVec/sum(chrLengthVec)
reads <- data.frame()
for(chr in 1:length(chrVec)){
reads <- rbind(reads, generateRandomReadsBED(chrVec[chr], numReads*percentTotalLengths[chr], chrLengthVec[chr], readLength))
}
return(reads[sample(1:length(reads), size=length(reads), replace=FALSE), ])
}
multiChrReads(c(1,2), 200, c(1000,3000), 50)
multiChrReads(c(1,2), 200, c(1000,3000), 50)
multiChrReads(c(1,2), 200, c(1000,3000), 50)
multiChrReads <- function(chrVec, numReads, chrLengthVec, readLength){
## returns approx number of reads
percentTotalLengths <- chrLengthVec/sum(chrLengthVec)
reads <- data.frame()
for(chr in 1:length(chrVec)){
reads <- rbind(reads, generateRandomReadsBED(chrVec[chr], numReads*percentTotalLengths[chr], chrLengthVec[chr], readLength))
}
return(reads[sample(1:dim(reads)[1], size=dim(reads)[1], replace=FALSE), ])
}
multiChrReads(c(1,2), 200, c(1000,3000), 50)
multiChrReads <- function(chrVec, numReads, chrLengthVec, readLength){
## returns approx number of reads
percentTotalLengths <- chrLengthVec/sum(chrLengthVec)
reads <- data.frame()
for(chr in 1:length(chrVec)){
reads <- rbind(reads, generateRandomReadsBED(chrVec[chr], numReads*percentTotalLengths[chr], chrLengthVec[chr], readLength))
}
reads <- reads[sample(1:dim(reads)[1], size=dim(reads)[1], replace=FALSE), ]
return(reads)
}
multiChrReads(c(1,2), 200, c(1000,3000), 50)
multiChrReads <- function(chrVec, numReads, chrLengthVec, readLength){
## returns approx number of reads
percentTotalLengths <- chrLengthVec/sum(chrLengthVec)
reads <- data.frame()
for(chr in 1:length(chrVec)){
reads <- rbind(reads, generateRandomReadsBED(chrVec[chr], numReads*percentTotalLengths[chr], chrLengthVec[chr], readLength))
}
reads <- data.frame(reads[sample(1:dim(reads)[1], size=dim(reads)[1], replace=FALSE), ])
return(reads)
}
multiChrReads(c(1,2), 200, c(1000,3000), 50)
multiChrPairedReads <- function(chrVec, numReads, chrLengthVec, readLength){
pairedReads <- cbind(multiChrReads(chrVec, numReads, chrLengthVec, readLength), multiChrReads(chrVec, numReads, chrLengthVec, readLength)[sample(1:numReads, numReads, replace=FALSE),])
return(pairedReads)
}
multiChrPairedReads(c(1,2), 200, c(1000,3000), 50)
reads <- multiChrPairedReads(c(1,2), 200, c(1000,3000), 50)
reads
reads[order(reads[,1])]
order(reads[ ,1])
reads[order(reads[ ,1]),]
nascentStrandMass <- function(Tns, Tcc, N, Nori, L){
## Returns theoretical ug amount of NS you start with when you use N cells
## should consider this MAX amount you would end up with (though it may not be max amount started with)
# Dns is desired amount in ug of NS
#Theoretical Estimation of Short Nascent Strands (Cadoret, 2008):
#
#Y = 2*(Tns/Tcc)*N*Nori*L*E
# To calculate Nori need to know genome size, length of S phase, and
# replication fork speed.  Then you can say that in order for the genome to
# be replicated inside this period of time, X many origins need to fire (at
# minimum). So this will give you a conservative estimate
lifespanNSgivenSizeRange = Tns
## Cadoret used 2 minutes.. really at 1500 bp/minute its probably between 1 minute (1500bp)  to 2 minutes (at high end, 3kb)
cellCycleLength = Tcc
# Hela ~24 hr, 1440 min; MCF7 ~30hr (Cinizia said ~30, but varies down to 25, 1500min)
numCellsUsed = N
## Cinizia says 10^7
minNumOrigins = Nori ## min num needed to replicate genome in give time frame of S-phase
ntWeight = (5.05050505*10^-16); #in ug
### I believe cadoret uses that, I get this 5.429103e-16
avgNSlen = L
# Good to use ~1500, but anywhere from 750-1500 are worth trying
proportionOfCellCycleNSexistsFor = lifespanNSgivenSizeRange/cellCycleLength
totNumORIs = numCellsUsed*minNumOrigins ## not all firing
proportionORIsCaughtWithCorrectSizeNSs = proportionOfCellCycleNSexistsFor*totNumORIs
totalNasStrandAtTwoPerORI = 2*proportionORIsCaughtWithCorrectSizeNSs
totalLenNS = avgNSlen*totalNasStrandAtTwoPerORI
totalMassNS = totalLenNS*ntWeight ## in ug
totalMassNSinNanoGram = totalMassNS*1000
return(value=totalMassNSinNanoGram)
# probably you should expect less as this is the amount available.
#the general purpose DNA washes will remove up to half of everything each time (should use AMPure)
}
nascentStrandMass(2, 90, 2500000000, 350, 1500)
nascentStrandMass(2, 30*60, 10000000, 60000, 1500)
nascentStrandMass(2, 30*60, 10000000, 30000, 1500)
nascentStrandMass(2, 30*60, 10000000, 90000, 1500)
nascentStrandMass(2, 24*60, 10000000, 90000, 1500)
nascentStrandMass(2, 90, 10000000, 350, 1500)
nascentStrandMass(2, 90, 50000000, 350, 1500)
nascentStrandMass(2, 90, 100000000, 350, 1500)
nascentStrandMass(2, 90, 2500000000, 350, 1500)
nascentStrandMass(2, 90, 1000000000, 350, 1500)
nascentStrandMass(2, 90, 100000000, 350, 1500)
ls()
quit()
15*12
15*12/60
12*10/60
14*10/60
14*10/60 + 0.5
12*10/60 + 0.5
180e+6*200/1
180e+6*200/18e+6
180e+6*200/18e+6/12
180e+6*200/18e+6/9
180e+6*200/18e0+6/9
180e+6*200/180e+6/9
180e+6*200/180e+6/12
180e+6/180e+6/12
100*180e+6/180e+6/12
200*180e+6/180e+6/12
500*180e+6/180e+6/12
500*180e+6/180e+6/9
plot(c(0,2,3), c(3,9, 27))
plot(c(0,2,3), c(3,9, 27), xlab="days", ylab="cell count", main="population growth over time")
plot(c(0,2,3), c(3,9, 27), xlab="days", ylab="cell count", main="population growth over time", type="l")
plot(c(0,2,3), c(3,9, 27), xlab="days", ylab="cell count", main="population growth over time", type="b")
mod = loess(c(3,9,27) ~ c(0,2,3))
lines(c(0,2,3),c(1,2,3))
points(c(0,2,3),c(1,2,3))
colors()
plot(c(0,2,3), c(3,9, 27), xlab="days", ylab="cell count", main="population growth over time", type="b")
plot(c(0,2,3), c(3,9, 27), xlab="days", ylab="cell count", main="population growth over time", type="b", xaxt="")
plot(c(0,2,3), c(3,9, 27), xlab="days", ylab="cell count", main="population growth over time", type="b", xaxt="n")
axis(side=1, c(0,1,2,3))
axis(side=1, c(0,1,2,3), names=c("d","f","e"))
axis(side=1, c(0,1,2,3), name=c("d","f","e"))
axis(side=1, c(0,1,2,3), label=c("d","f","e"))
axis(side=1, c(0,1,2,3), label=c("d","f","e","r"))
plot(c(0,2,3), c(3,9, 27), xlab="days", ylab="cell count", main="population growth over time", type="b", xaxt="n")
axis(side=1, c(0,1,2,3), label=c("d","f","e","r"))
plot(c(0,2,3), c(3,9, 27), xlab="days", ylab="cell count", main="population growth over time", type="b", xaxt="n")
axis(side=1, c(0,1,2,3), label=c("Day 1","Day 2","Day 3","Day 4"))
axis(side=1, c(0,1,2,3), label=c("Day 0","Day 1","Day 2","Day 3"))
plot(c(0,2,3), c(3,9, 27), xlab="days", ylab="cell count", main="population growth over time", type="b", xaxt="n")
axis(side=1, c(0,1,2,3), label=c("Day 0","Day 1","Day 2","Day 3"))
?update.packages
update.packages(checkBuilt=TRUE)
update.packages(checkBuilt=TRUE)
library(VennDiagram)
version()
R.version()
R.version
library(lm)
library(glm)
installed.packages()
library(zoo)
data <- read.table("~/Downloads/HET_MvsKO_M.genes.de.xlsx", delim="csv")
?read.table
data <- read.table("~/Downloads/HET_MvsKO_M.genes.de.xlsx", sep="csv")
data <- read.table("~/Downloads/HET_MvsKO_M.genes.de.xlsx", sep=",")
data <- read.table("~/Downloads/HET_MvsKO_M.genes.de.csv", sep=",")
data
data <- read.table("~/Downloads/HET_MvsKO_M.genes.de.txt)
)
data <- read.table("~/Downloads/HET_MvsKO_M.genes.de.txt")
head(data)
heatmap(data$V6)
heatmap(as.matrix(data$V6))
as.matrix(data$V6)
data$V6
data$V5
heatmap(data$V5)
heatmap(as.matrix(data$V5))
heatmap(as.matrix(data[,5:6]))
heatmap(as.matrix(data[,c(1,5)]))
heatmap(as.matrix(data[,c(4,5)]))
heatmap(t(as.matrix(data[,c(4,5)])))
image(data$V5)
image(as.matrix(data$V5))
library(lattice)
levelplot(as.matrix(data$V5))
levelplot(t(as.matrix(data$V5)))
?levelplot
levelplot(data$V6[order(data$V6)])
data$V6[order(data$V6)]
levelplot(data$V5[order(data$V5)])
order(data$V5)
data$V5[order(data$V5)]
data$V1[order(data$V5)]
sqrt(5)
setwd("~/searchPaths/bitbucket/squiggler/example_dtw/")
source("~/searchPaths/bitbucket/squiggler/example_dtw/hmm_functions.R")
emissions = as.matrix(data.frame(A=c(10,sqrt(5)), C=c(40,sqrt(5)), G=c(70,sqrt(5)), T=c(100,sqrt(5))))
a = c(0.1,  0.2,	0.3,	0.4)
c = c(0.4,  0.3,	0.2,	0.1)
g = c(0.25,  0.25,	0.15,	0.35)
t = c(0.3,  0.2,	0.3,	0.2)
transitions = matrix(data = c(a,c,g,t), nrow = 4, byrow = TRUE)
initial = c(0.25,0.25,0.25,0.25)
states = c("A","C","G","T")
answer <- generate.emissions(emissions, transitions, initial, states, length=10)
answer
transitions = matrix(data = rep(uniform, 4), nrow = 4, byrow = TRUE)
uniform = c(0.25,0.25,0.25,0.25)
transitions = matrix(data = rep(uniform, 4), nrow = 4, byrow = TRUE)
emissions = as.matrix(data.frame(A=c(40,2), C=c(50,2.5), G=c(60,2.2), T=c(70,1.8)))
answer <- generate.emissions(emissions, transitions, initial, states, length=10)
answer
f <- forward(emissions, transitions, initial, states, answer$emitted.data)
b <- backward(emissions, transitions, initial, states, answer$emitted.data)
d <- prob.data(f)
sum(f[,1]*b[,1])/d
c <- centroid(f,b,states)
compare.statepath(c$centroid.path, answer$statepath)
v$viterbi_seq
c$centroid.seq
answer$statepathseq
answer <- generate.emissions(emissions, transitions, initial, states, length=10)
fl <- forward.long(emissions, transitions, initial, states, answer$emitted.data)
dl <- prob.data.long(Forward = fl$forward, scalefactors = fl$scales)
bl <- backward.long(emissions, transitions, initial, states, answer$emitted.data)
v <- viterbi(emissions, transitions, initial, states, answer$emitted.data)
cl <- centroid.long(Forward = fl$forward, F_scales = fl$scales, Backward = bl$backward, B_scales = bl$scales, states)
compare.statepath(v$viterbi_path, answer$statepath)
compare.statepath(cl$centroid.path, answer$statepath)
compare.seq(v$viterbi_seq, answer$statepathseq)
compare.seq(cl$centroid.seq, answer$statepathseq)
answer <- generate.emissions(emissions, transitions, initial, states, length=10)
fl <- forward.long(emissions, transitions, initial, states, answer$emitted.data)
dl <- prob.data.long(Forward = fl$forward, scalefactors = fl$scales)
bl <- backward.long(emissions, transitions, initial, states, answer$emitted.data)
v <- viterbi(emissions, transitions, initial, states, answer$emitted.data)
cl <- centroid.long(Forward = fl$forward, F_scales = fl$scales, Backward = bl$backward, B_scales = bl$scales, states)
compare.statepath(v$viterbi_path, answer$statepath)
compare.statepath(cl$centroid.path, answer$statepath)
emissions = as.matrix(data.frame(A=c(40,2), C=c(50,2.5), G=c(60,2.2), T=c(70,1.8)))
transitions = matrix(data = rep(uniform, 4), nrow = 4, byrow = TRUE)
initial = c(0.25,0.25,0.25,0.25)
states = c("A","C","G","T")
answer <- generate.emissions(emissions, transitions, initial, states, length=10)
answer
fl <- forward.long(emissions, transitions, initial, states, answer$emitted.data)
dl <- prob.data.long(Forward = fl$forward, scalefactors = fl$scales)
bl <- backward.long(emissions, transitions, initial, states, answer$emitted.data)
v <- viterbi(emissions, transitions, initial, states, answer$emitted.data)
cl <- centroid.long(Forward = fl$forward, F_scales = fl$scales, Backward = bl$backward, B_scales = bl$scales, states)
compare.statepath(v$viterbi_path, answer$statepath)
answer <- generate.emissions(emissions, transitions, initial, states, length=10)
fl <- forward.long(emissions, transitions, initial, states, answer$emitted.data)
dl <- prob.data.long(Forward = fl$forward, scalefactors = fl$scales)
bl <- backward.long(emissions, transitions, initial, states, answer$emitted.data)
v <- viterbi(emissions, transitions, initial, states, answer$emitted.data)
cl <- centroid.long(Forward = fl$forward, F_scales = fl$scales, Backward = bl$backward, B_scales = bl$scales, states)
compare.statepath(v$viterbi_path, answer$statepath)
compare.statepath(cl$centroid.path, answer$statepath)
answer
